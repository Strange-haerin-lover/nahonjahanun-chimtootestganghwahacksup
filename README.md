# nahonjahanun-chimtootestganghwahacksup

**액션 공간 만들기**
1. 액션 정의 yaml 계층구조 만들기
2. 결정 프로세스에서 툴 선택 -> 기능 선택 -> 세부적인 옵션이나 파라미터 선택


**중요**
보상 시스템
1. 외제적 보상
- FLAG 발견
- 오류
2. 내제적 보상
- 호기심 보상 -> 행동 스토리지에 없는 행동을 하게 되면 호기심 점수 보상
- 예측 오차 기반: 내가 다음 상태를 얼마나 잘 맞췄나? -> 툴의 사용 방법과 효용을 터득(중요!)


꼭 들어가야 하는 요소
1. 월드 모델 -> 이 행동을 했을때 나올 가상의 예상 점수 예측
2. RNN으로 신념 상태 생성 -> 사후 보상(이전에 높았던 점수와 유사한 행동 패턴에 대해 추가 점수 부여)
3. 현재 상태 점수: 보상 시스템에 의해 부여 
4. 보상 함수: 현재 상태 점수에 신념 상태 점수 추가해서
5. policy: 이전 상태 보상을 바탕으로 각 행동에 대하여 확률 조정
6. 행동 스토리지: 현재 한 행동을 스토리지 파일에 저장하고 없다면 보상 시스템에 의한 호기심 보상, 있다면 현재 보상에 비례해서 policy가 해당 행동의 확률 조정
7. 지식 스토리지: 현재 상태에서 나온 새로운 정보를 저장 -> 후대 행동에서 매개변수로 사용
8. 대망의 결정 프로세스: 보상 적용(RNN 신념 상태 + 현재 상태로 보상 생성) -> policy가 행동별 확률 업데이트 -> policy에서 만든 행동 리스트에서 랜덤으로 뽑은 행동 5개 선별(확률 높은게 뽑히겠지?) -> 5개의 행동을 월드 모델에 넣어서 예상 점수를 예측 -> 예상 점수가 가장 높은 것을 실행

**서론**

침투 테스트를 자동화 하는 강화학습 에이전트를 개발한다
아무것도 모르는 상태에서 시작
knowledge database에 새로 발견한 정보를 저장 이 정보가 어디에 어떻게 쓰일지는 추후 학습을 통해서만 알 수 있다
미리 알려주는 지표의 유형도 없다
우리가 알려주는 것은 툴들의 사용을 위한 문법 만을 알려준다(이것도 모르게 하려 했는데.....)
인공지능은 스스로 규칙을 만들어야 한다(고수들이 자신만의 무언가가 있는듯이)
스스로 규칙을 만드는데 줄 수 있는 가이드 곧 보상이 호기심 보상이나, 에러로 인한 마이너스 보상 그리고 FLAG 발견에 의한 성공 보상 밖에 없다(더 있으면 좋다 하지만 그 보상 지표로 인해 미리 중간 목표를 세워주거나 위의 취지 곧 자율성 최대화에 위배되어서는 안된다)

우리에게 필요한것은 매우 적은 보상으로 자신 만의 창의적인 침투 테스트를 해내는 강화학습 코어이다
그것을 개발해야 한다

에이전트에게 주어지는 정보는 다음으로 제한된다
1. 툴의 기능 사용 방법 - 오직 문법만 -> 툴과 그 밑의 기능들은 정의 해줄까 미리 탬플릿 처럼 해서 기능(필요 인자들...) 이런식도 괜찮을듯
2. 자신이 실행 한 명령어와 그에 따라 나온 정보 들의 히스토리(기록)
3. knowledge database의 자신이 얻은 정보들(라벨링 안되어 있음)

보상 시스템
1. 외제적 보상
- FLAG 발견
- 오류
2. 내제적 보상
- 호기심 보상
- 예측 오차 기반: 내가 다음 상태를 얼마나 잘 맞췄나? -> 툴의 사용 방법과 효용을 터득

(중요!) 구성요소
1. 월드 모델 -> 이 행동을 하면 다음에 어떤 상태가 될지 예측하는 모델
2. 결정 프로세스: 폴리시로 확률 분포를 만든 다음에 상위 몇개의 행동들을 선별해서 그것들을 월드 모델에 넣어서 가장 예상 점수(점수는 RNN의 신념 상태를 포함한다)가 높은 것을 실행한다.
- 폴리시는 이전 상태 보상을 가지고 훈련된다 이전 상태 보상으로 그 때 사용 했던 행동에 점수를 매기고 그 행동을 실행 할 확률을 부여 한다
- 보상: 사전 보상(RNN이 히스토리 읽어서 만든 신념 상태(ㅋㅋ), 현재 상태), 사후 보상
- policy는 행동에 대한 각의 확률 표

!!아이디어(쓸데없을 확률 높음)
1. LSTM과 같은 순환 신경망을 응용 현재 까지의 히스토리를 이용해 다음 스텝을 예측
- 순환 신경망을 사용하여 다음 상태를 추천하고 그것도 에이전트의 다음 스텝 설계에 사용
- 구체적으로 현재의 보상 시스템은 사후 보상이다 하지만 이건 결정하기 사전에 받는 계시? 같은 거니까 다르게 처리해야 한다 -> 결정 프로세스를 알아야 한다
2. 

느낀점
1. 수학적 베이스가 적어서 할 수 있는 방법 및 알고리즘이 매우 제한적이다




